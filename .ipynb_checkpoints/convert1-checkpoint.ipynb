{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/a8/f051a1ec9a08312d76a5b8b663d831c91de24ec80a073a3303a1617aaef1/opencv_python-4.1.1.26-cp37-cp37m-macosx_10_8_x86_64.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (51.6MB)\n",
      "\u001b[K     |████████████████████████████████| 51.6MB 19.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from opencv-python) (1.16.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.1.1.26\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('HW1Final/b_out.png',0)\n",
    "\n",
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "#plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(img.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "#plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_in = cv2.imread('HW1Final/input11.jpeg')\n",
    "\n",
    "b,g,r = cv2.split(img_in)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "cl1 = clahe.apply(b)\n",
    "cl2 = clahe.apply(g)\n",
    "cl3 = clahe.apply(r)\n",
    "\n",
    "img_out = cv2.merge((cl1, cl2, cl3))\n",
    "\n",
    "cv2.imwrite('HW1Final/out_2.png',img_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-57-b5c7204da081>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-b5c7204da081>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    b,g,r = cv2.split(img_in)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#bgr = cv2.imread('input11.jpeg',0)\n",
    "\n",
    "lab = cv2.imread('input11.jpeg',0)#cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "#lab_planes = cv2.split(lab)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
    "\n",
    "lab = clahe.apply(lab)\n",
    "\n",
    "    b,g,r = cv2.split(img_in)\n",
    "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
    "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
    "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
    "    \n",
    "    cdf_b = np.cumsum(h_b)  \n",
    "    cdf_g = np.cumsum(h_g)\n",
    "    cdf_r = np.cumsum(h_r)\n",
    "    \n",
    "   \n",
    "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
    "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
    "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
    "  \n",
    "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
    "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
    "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
    "\n",
    "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
    "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
    "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
    "\n",
    "    img_b = cdf_final_b[b]\n",
    "    img_g = cdf_final_g[g]\n",
    "    img_r = cdf_final_r[r]\n",
    "    \n",
    "    \n",
    "  \n",
    "    #print(img_b)\n",
    "    #print(img_g)\n",
    "    #print(img_r)\n",
    " \n",
    "    img_out = cv2.merge((img_b, img_g, img_r))\n",
    "\n",
    "cv2.imwrite('res11.png',lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument '%s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-b06326a29b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mequ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalizeHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#stacking images side-by-side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HW1Final/res23556566.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument '%s'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('HW1Final/23556566.jpeg',0)\n",
    "equ = cv2.equalizeHist(img)\n",
    "res = np.hstack((img,equ)) #stacking images side-by-side\n",
    "cv2.imwrite('HW1Final/res23556566.png',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help_message():\n",
    "    print(\"Usage: [Question_Number] [Input_Options] [Output_Options]\")\n",
    "    print(\"[Question Number]\")\n",
    "    print(\"1 Histogram equalization\")\n",
    "    print(\"2 Frequency domain filtering\")\n",
    "    print(\"3 Laplacian pyramid blending\")\n",
    "    print(\"[Input_Options]\")\n",
    "    print(\"Path to the input images\")\n",
    "    print(\"[Output_Options]\")\n",
    "    print(\"Output directory\")\n",
    "    print(\"Example usages:\")\n",
    "    print(sys.argv[0] + \" 1 \" + \"[path to input image] \" +\n",
    "          \"[output directory]\")  # Single input, single output\n",
    "    print(sys.argv[0] + \" 2 \" + \"[path to input image1] \" +\n",
    "          \"[path to input image2] \" +\n",
    "          \"[output directory]\")  # Two inputs, three outputs\n",
    "    print(sys.argv[0] + \" 3 \" + \"[path to input image1] \" +\n",
    "          \"[path to input image2] \" +\n",
    "          \"[output directory]\")  # Two inputs, single output\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# ======== Question 1: Histogram equalization =======\n",
    "# ===================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(img_in):\n",
    "\n",
    "    # Write histogram equalization here\n",
    "    b,g,r = cv2.split(img_in)\n",
    "#     h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
    "#     h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
    "#     h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
    "    \n",
    "#     cdf_b = np.cumsum(h_b)  \n",
    "#     cdf_g = np.cumsum(h_g)\n",
    "#     cdf_r = np.cumsum(h_r)\n",
    "    \n",
    "   \n",
    "#     cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
    "#     cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
    "#     cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
    "  \n",
    "#     cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
    "#     cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
    "#     cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
    "\n",
    "#     cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
    "#     cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
    "#     cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
    "\n",
    "#     img_b = cdf_final_b[b]\n",
    "#     img_g = cdf_final_g[g]\n",
    "#     img_r = cdf_final_r[r]\n",
    "  \n",
    "#     #print(img_b)\n",
    "#     #print(img_g)\n",
    "#     #print(img_r)\n",
    " \n",
    "#     img_out = cv2.merge((img_b, img_g, img_r))\n",
    "    #print(img_out)\n",
    "    #print(\"hist\") \n",
    "\n",
    "\n",
    "    ##validation\n",
    "    equ_b = cv2.equalizeHist(b)\n",
    "    equ_g = cv2.equalizeHist(g)\n",
    "    equ_r = cv2.equalizeHist(r)\n",
    "    img_out = cv2.merge((equ_b, equ_g, equ_r))\n",
    "    #print(equ)\n",
    "    #cv2.imwrite('output_name.png', equ)\n",
    "\n",
    "    return True, img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question1(inp,output):\n",
    "\n",
    "    # Read in input images\n",
    "    input_image = cv2.imread(inp, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Histogram equalization\n",
    "    succeed, output_image = histogram_equalization(input_image)\n",
    "\n",
    "    # Write out the result\n",
    "    output_name = output + \"output1.png\"\n",
    "    cv2.imwrite(output_name, output_image)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# ===== Question 2: Frequency domain filtering ======\n",
    "# ===================================================\n",
    "\n",
    "\n",
    "def high_pass_filter(img_in):\n",
    "\n",
    "    # Write low pass filter here\n",
    "    img_in = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "    dft = cv2.dft(np.float32(img_in),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "\n",
    "    rows, cols = img_in.shape\n",
    "    crow,ccol = rows//2 , cols//2\n",
    "\n",
    "    dft_shift[crow-10:crow+10, ccol-10:ccol+10] = 0\n",
    "    dft_ishift = np.fft.ifftshift(dft_shift)\n",
    "\n",
    "\n",
    "    img_out = cv2.idft(dft_ishift)\n",
    "    img_out = cv2.magnitude(img_out[:,:,0],img_out[:,:,1])\n",
    "\n",
    "    img_out1 = np.ma.masked_equal(img_out,0)\n",
    "    img_out2 = (img_out1 - img_out1.min())*255/(img_out1.max()-img_out1.min())\n",
    "    img_out = np.ma.filled(img_out2,0).astype('uint8') \n",
    "    return True, img_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(img_in):\n",
    "    \n",
    "    img_in = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "    dft = cv2.dft(np.float32(img_in),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    #magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "    rows, cols = img_in.shape\n",
    "    crow,ccol = rows//2 , cols//2\n",
    "# create a mask first, center square is 1, remaining all zeros\n",
    "    mask = np.zeros((rows,cols,2),np.uint8)\n",
    "    mask[crow-10:crow+10, ccol-10:ccol+10] = 1\n",
    "# apply mask and inverse DFT\n",
    "    fshift = dft_shift*mask\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_out = cv2.idft(f_ishift)\n",
    "    img_out = cv2.magnitude(img_out[:,:,0],img_out[:,:,1])\n",
    "\n",
    "    img_out1 = np.ma.masked_equal(img_out,0)\n",
    "    img_out2 = (img_out1 - img_out1.min())*255/(img_out1.max()-img_out1.min())\n",
    "    img_out = np.ma.filled(img_out2,0).astype('uint8') \n",
    "\n",
    "    return True, img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deconvolution(img_in):\n",
    "    #img_in = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY) \n",
    "    gk = cv2.getGaussianKernel(21,5)\n",
    "    gk = gk * gk.T\n",
    "\n",
    "    def ft(im, newsize=None):\n",
    "      dft = np.fft.fft2(np.float32(im),newsize)\n",
    "      return np.fft.fftshift(dft)\n",
    "\n",
    "    def ift(shift):\n",
    "      f_ishift = np.fft.ifftshift(shift)\n",
    "      img_back = np.fft.ifft2(f_ishift)\n",
    "      return np.abs(img_back)\n",
    "\n",
    "    imf = ft(img_in, (img_in.shape[0],img_in.shape[1])) # make sure sizes match\n",
    "    gkf = ft(gk, (img_in.shape[0],img_in.shape[1])) # so we can multiple easily\n",
    "    imconvf = imf/gkf\n",
    "\n",
    "# now for example we can reconstruct the blurred image from its FT\n",
    "    blurred = ift(imconvf)\n",
    "# # now for example we can reconstruct the blurred image from its FT\n",
    "\n",
    "    img_out = blurred  # Deconvolution result\n",
    "    img_out1 = np.ma.masked_equal(img_out,0)\n",
    "    img_out2 = (img_out1 - img_out1.min())*255/(img_out1.max()-img_out1.min())\n",
    "    img_out = np.ma.filled(img_out2,0).astype('uint8')\n",
    "    return True, img_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question2():\n",
    "\n",
    "    # Read in input images\n",
    "    input_image1 = cv2.imread(sys.argv[2], cv2.IMREAD_COLOR)\n",
    "    #input_image2 = cv2.imread(sys.argv[3], cv2.IMREAD_COLOR)\n",
    "    input_image2  = cv2.imread(sys.argv[3], cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "    # Low and high pass filter\n",
    "    succeed1, output_image1 = low_pass_filter(input_image1)\n",
    "    succeed2, output_image2 = high_pass_filter(input_image1)\n",
    "\n",
    "    # Deconvolution\n",
    "    succeed3, output_image3 = deconvolution(input_image2)\n",
    "\n",
    "    # Write out the result\n",
    "    output_name1 = sys.argv[4] + \"output2LPF.png\"\n",
    "    output_name2 = sys.argv[4] + \"output2HPF.png\"\n",
    "    output_name3 = sys.argv[4] + \"output2deconv.png\"\n",
    "    cv2.imwrite(output_name1, output_image1)\n",
    "    cv2.imwrite(output_name2, output_image2)\n",
    "    cv2.imwrite(output_name3, output_image3)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# ===== Question 3: Laplacian pyramid blending ======\n",
    "# ===================================================\n",
    "\n",
    "\n",
    "def laplacian_pyramid_blending(img_in1, img_in2):\n",
    "    # generate Gaussian pyramid for A\n",
    "    A = img_in1.copy()\n",
    "    #A = cv2.cvtColor(A, cv2.COLOR_BGR2RGB)\n",
    "    A = A[:,:A.shape[0]]\n",
    "    \n",
    "    # generate Gaussian pyramid for B\n",
    "    B = img_in2.copy()\n",
    "    #B = cv2.cvtColor(B, cv2.COLOR_BGR2RGB)\n",
    "    B = B[:A.shape[0],:A.shape[0]]\n",
    "\n",
    "    gpA = [A]\n",
    "    for i in range(6):\n",
    "        A = cv2.pyrDown(gpA[i])\n",
    "        gpA.append(A)\n",
    "    # generate Gaussian pyramid for B\n",
    "    \n",
    "    gpB = [B]\n",
    "    for i in xrange(6):\n",
    "        B = cv2.pyrDown(gpB[i])\n",
    "        gpB.append(B)\n",
    "    # generate Laplacian Pyramid for A\n",
    "    lpA = [gpA[5]]\n",
    "    for i in xrange(5,0,-1):\n",
    "        size = (gpA[i-1].shape[1], gpA[i-1].shape[0])\n",
    "        GE = cv2.pyrUp(gpA[i], dstsize = size)\n",
    "        L = cv2.subtract(gpA[i-1],GE)\n",
    "        lpA.append(L)\n",
    "    # generate Laplacian Pyramid for B\n",
    "    lpB = [gpB[5]]\n",
    "    for i in xrange(5,0,-1):\n",
    "        size = (gpB[i-1].shape[1], gpB[i-1].shape[0])\n",
    "        GE = cv2.pyrUp(gpB[i], dstsize = size)\n",
    "        L = cv2.subtract(gpB[i-1],GE)\n",
    "        lpB.append(L)\n",
    "    # Now add left and right halves of images in each level\n",
    "    LS = []\n",
    "    for la,lb in zip(lpA,lpB):\n",
    "        rows,cols,dpt = la.shape\n",
    "        ls = np.hstack((la[:,0:cols/2], lb[:,cols/2:]))\n",
    "        LS.append(ls)\n",
    "    # now reconstruct\n",
    "    ls_ = LS[0]\n",
    "    for i in xrange(1,6):\n",
    "        size = (LS[i].shape[1], LS[i].shape[0])\n",
    "        ls_ = cv2.pyrUp(ls_, dstsize = size)\n",
    "        ls_ = cv2.add(ls_, LS[i])\n",
    "    # image with direct connecting each half\n",
    "    # Write laplacian pyramid blending codes here\n",
    "    img_out = ls_  # Blending result\n",
    "\n",
    "    return True, img_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question3():\n",
    "\n",
    "    # Read in input images\n",
    "    input_image1 = cv2.imread(sys.argv[2], cv2.IMREAD_COLOR)\n",
    "    input_image2 = cv2.imread(sys.argv[3], cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Laplacian pyramid blending\n",
    "    succeed, output_image = laplacian_pyramid_blending(input_image1, input_image2)\n",
    "    # Write out the result\n",
    "    output_name = sys.argv[4] + \"output3.png\"\n",
    "    cv2.imwrite(output_name, output_image)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: [Question_Number] [Input_Options] [Output_Options]\n",
      "[Question Number]\n",
      "1 Histogram equalization\n",
      "2 Frequency domain filtering\n",
      "3 Laplacian pyramid blending\n",
      "[Input_Options]\n",
      "Path to the input images\n",
      "[Output_Options]\n",
      "Output directory\n",
      "Example usages:\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py 1 [path to input image] [output directory]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py 2 [path to input image1] [path to input image2] [output directory]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py 3 [path to input image1] [path to input image2] [output directory]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    question_number = -1\n",
    "\n",
    "    # Validate the input arguments\n",
    "    if (len(sys.argv) < 4):\n",
    "        help_message()\n",
    "        sys.exit()\n",
    "    else:\n",
    "        question_number = int(sys.argv[1])\n",
    "\n",
    "        if (question_number == 1 and not (len(sys.argv) == 4)):\n",
    "            help_message()\n",
    "            sys.exit()\n",
    "        if (question_number == 2 and not (len(sys.argv) == 5)):\n",
    "            help_message()\n",
    "            sys.exit()\n",
    "        if (question_number == 3 and not (len(sys.argv) == 5)):\n",
    "            help_message()\n",
    "            sys.exit()\n",
    "        if (question_number > 3 or question_number < 1 or len(sys.argv) > 5):\n",
    "            print(\"Input parameters out of bound ...\")\n",
    "            sys.exit()\n",
    "\n",
    "    function_launch = {\n",
    "        1: Question1,\n",
    "        2: Question2,\n",
    "        3: Question3,\n",
    "    }\n",
    "\n",
    "    # Call the function\n",
    "    function_launch[1]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-17d94a2d8837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQuestion1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2dc55ae16f11>\u001b[0m in \u001b[0;36mQuestion1\u001b[0;34m(inp, output)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Histogram equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msucceed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistogram_equalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Write out the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ac7c54fa7678>\u001b[0m in \u001b[0;36mhistogram_equalization\u001b[0;34m(img_in)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Write histogram equalization here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mh_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mh_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "Question1(\"input1.jpg\",\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "  \n",
    "originalImage = cv2.imread('HW1Final/input3256.jpeg')\n",
    "grayImage = cv2.cvtColor(originalImage, cv2.COLOR_BGR2GRAY)\n",
    "(thresh, blackAndWhiteImage) = cv2.threshold(grayImage, 127, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "  \n",
    "cv2.imwrite('blackAndWhiteImage.png', blackAndWhiteImage)\n",
    "cv2.imwrite('grayImage.png', grayImage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
