{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/site-packages (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/shilpibhattacharyya/Library/Python/3.7/lib/python/site-packages (from opencv-python) (1.17.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('IMG_0545.JPG',0)\n",
    "\n",
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "#plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(img.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "#plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_in = cv2.imread('IMG_0545.JPG')\n",
    "\n",
    "b,g,r = cv2.split(img_in)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(7,7))\n",
    "\n",
    "cl1 = clahe.apply(b)\n",
    "cl2 = clahe.apply(g)\n",
    "cl3 = clahe.apply(r)\n",
    "\n",
    "img_out = cv2.merge((cl1, cl2, cl3))\n",
    "\n",
    "cv2.imwrite('res.png',img_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bgr = cv2.imread('input11.jpeg',0)\n",
    "\n",
    "lab = cv2.imread('IMG_0545.JPG',0)#cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "#lab_planes = cv2.split(lab)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
    "\n",
    "lab = clahe.apply(lab)\n",
    "\n",
    "b,g,r = cv2.split(img_in)\n",
    "h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
    "h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
    "h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
    "\n",
    "cdf_b = np.cumsum(h_b)  \n",
    "cdf_g = np.cumsum(h_g)\n",
    "cdf_r = np.cumsum(h_r)\n",
    "\n",
    "\n",
    "cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
    "cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
    "cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
    "\n",
    "cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
    "cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
    "cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
    "\n",
    "cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
    "cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
    "cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
    "\n",
    "img_b = cdf_final_b[b]\n",
    "img_g = cdf_final_g[g]\n",
    "img_r = cdf_final_r[r]\n",
    "\n",
    "\n",
    "\n",
    "#print(img_b)\n",
    "#print(img_g)\n",
    "#print(img_r)\n",
    "\n",
    "img_out = cv2.merge((img_b, img_g, img_r))\n",
    "\n",
    "cv2.imwrite('res11.png',lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('IMG_0545.JPG',0)\n",
    "equ = cv2.imread('output_name.png',0)\n",
    "res = np.hstack((img,equ)) #stacking images side-by-side\n",
    "cv2.imwrite('res_out.png',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help_message():\n",
    "    print(\"Usage: [Question_Number] [Input_Options] [Output_Options]\")\n",
    "    print(\"[Question Number]\")\n",
    "    print(\"1 Histogram equalization\")\n",
    "    print(\"2 Frequency domain filtering\")\n",
    "    print(\"3 Laplacian pyramid blending\")\n",
    "    print(\"[Input_Options]\")\n",
    "    print(\"Path to the input images\")\n",
    "    print(\"[Output_Options]\")\n",
    "    print(\"Output directory\")\n",
    "    print(\"Example usages:\")\n",
    "    print(sys.argv[0] + \" 1 \" + \"[path to input image] \" +\n",
    "          \"[output directory]\")  # Single input, single output\n",
    "    print(sys.argv[0] + \" 2 \" + \"[path to input image1] \" +\n",
    "          \"[path to input image2] \" +\n",
    "          \"[output directory]\")  # Two inputs, three outputs\n",
    "    print(sys.argv[0] + \" 3 \" + \"[path to input image1] \" +\n",
    "          \"[path to input image2] \" +\n",
    "          \"[output directory]\")  # Two inputs, single output\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# ======== Question 1: Histogram equalization =======\n",
    "# ===================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(img_in):\n",
    "\n",
    "    # Write histogram equalization here\n",
    "    b,g,r = cv2.split(img_in)\n",
    "#     h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
    "#     h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
    "#     h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
    "    \n",
    "#     cdf_b = np.cumsum(h_b)  \n",
    "#     cdf_g = np.cumsum(h_g)\n",
    "#     cdf_r = np.cumsum(h_r)\n",
    "    \n",
    "   \n",
    "#     cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
    "#     cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
    "#     cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
    "  \n",
    "#     cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
    "#     cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
    "#     cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
    "\n",
    "#     cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
    "#     cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
    "#     cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
    "\n",
    "#     img_b = cdf_final_b[b]\n",
    "#     img_g = cdf_final_g[g]\n",
    "#     img_r = cdf_final_r[r]\n",
    "  \n",
    "#     #print(img_b)\n",
    "#     #print(img_g)\n",
    "#     #print(img_r)\n",
    " \n",
    "#     img_out = cv2.merge((img_b, img_g, img_r))\n",
    "    #print(img_out)\n",
    "    #print(\"hist\") \n",
    "\n",
    "\n",
    "    ##validation\n",
    "    equ_b = cv2.equalizeHist(b)\n",
    "    equ_g = cv2.equalizeHist(g)\n",
    "    equ_r = cv2.equalizeHist(r)\n",
    "    img_out = cv2.merge((equ_b, equ_g, equ_r))\n",
    "    #print(equ)\n",
    "    #cv2.imwrite('output_name.png', equ)\n",
    "\n",
    "    return True, img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question1(inp,output):\n",
    "\n",
    "    # Read in input images\n",
    "    input_image = cv2.imread(inp, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Histogram equalization\n",
    "    succeed, output_image = histogram_equalization(input_image)\n",
    "\n",
    "    # Write out the result\n",
    "    output_name = output + \"output1.png\"\n",
    "    cv2.imwrite(output_name, output_image)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# ===== Question 2: Frequency domain filtering ======\n",
    "# ===================================================\n",
    "\n",
    "\n",
    "def high_pass_filter(img_in):\n",
    "\n",
    "    # Write low pass filter here\n",
    "    img_in = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "    dft = cv2.dft(np.float32(img_in),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "\n",
    "    rows, cols = img_in.shape\n",
    "    crow,ccol = rows//2 , cols//2\n",
    "\n",
    "    dft_shift[crow-10:crow+10, ccol-10:ccol+10] = 0\n",
    "    dft_ishift = np.fft.ifftshift(dft_shift)\n",
    "\n",
    "\n",
    "    img_out = cv2.idft(dft_ishift)\n",
    "    img_out = cv2.magnitude(img_out[:,:,0],img_out[:,:,1])\n",
    "\n",
    "    img_out1 = np.ma.masked_equal(img_out,0)\n",
    "    img_out2 = (img_out1 - img_out1.min())*255/(img_out1.max()-img_out1.min())\n",
    "    img_out = np.ma.filled(img_out2,0).astype('uint8') \n",
    "    return True, img_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(img_in):\n",
    "    \n",
    "    img_in = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "    dft = cv2.dft(np.float32(img_in),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    #magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "    rows, cols = img_in.shape\n",
    "    crow,ccol = rows//2 , cols//2\n",
    "# create a mask first, center square is 1, remaining all zeros\n",
    "    mask = np.zeros((rows,cols,2),np.uint8)\n",
    "    mask[crow-10:crow+10, ccol-10:ccol+10] = 1\n",
    "# apply mask and inverse DFT\n",
    "    fshift = dft_shift*mask\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_out = cv2.idft(f_ishift)\n",
    "    img_out = cv2.magnitude(img_out[:,:,0],img_out[:,:,1])\n",
    "\n",
    "    img_out1 = np.ma.masked_equal(img_out,0)\n",
    "    img_out2 = (img_out1 - img_out1.min())*255/(img_out1.max()-img_out1.min())\n",
    "    img_out = np.ma.filled(img_out2,0).astype('uint8') \n",
    "\n",
    "    return True, img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deconvolution(img_in):\n",
    "    #img_in = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY) \n",
    "    gk = cv2.getGaussianKernel(21,5)\n",
    "    gk = gk * gk.T\n",
    "\n",
    "    def ft(im, newsize=None):\n",
    "      dft = np.fft.fft2(np.float32(im),newsize)\n",
    "      return np.fft.fftshift(dft)\n",
    "\n",
    "    def ift(shift):\n",
    "      f_ishift = np.fft.ifftshift(shift)\n",
    "      img_back = np.fft.ifft2(f_ishift)\n",
    "      return np.abs(img_back)\n",
    "\n",
    "    imf = ft(img_in, (img_in.shape[0],img_in.shape[1])) # make sure sizes match\n",
    "    gkf = ft(gk, (img_in.shape[0],img_in.shape[1])) # so we can multiple easily\n",
    "    imconvf = imf/gkf\n",
    "\n",
    "# now for example we can reconstruct the blurred image from its FT\n",
    "    blurred = ift(imconvf)\n",
    "# # now for example we can reconstruct the blurred image from its FT\n",
    "\n",
    "    img_out = blurred  # Deconvolution result\n",
    "    img_out1 = np.ma.masked_equal(img_out,0)\n",
    "    img_out2 = (img_out1 - img_out1.min())*255/(img_out1.max()-img_out1.min())\n",
    "    img_out = np.ma.filled(img_out2,0).astype('uint8')\n",
    "    return True, img_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question2():\n",
    "\n",
    "    # Read in input images\n",
    "    input_image1 = cv2.imread(sys.argv[2], cv2.IMREAD_COLOR)\n",
    "    #input_image2 = cv2.imread(sys.argv[3], cv2.IMREAD_COLOR)\n",
    "    input_image2  = cv2.imread(sys.argv[3], cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "    # Low and high pass filter\n",
    "    succeed1, output_image1 = low_pass_filter(input_image1)\n",
    "    succeed2, output_image2 = high_pass_filter(input_image1)\n",
    "\n",
    "    # Deconvolution\n",
    "    succeed3, output_image3 = deconvolution(input_image2)\n",
    "\n",
    "    # Write out the result\n",
    "    output_name1 = sys.argv[4] + \"output2LPF.png\"\n",
    "    output_name2 = sys.argv[4] + \"output2HPF.png\"\n",
    "    output_name3 = sys.argv[4] + \"output2deconv.png\"\n",
    "    cv2.imwrite(output_name1, output_image1)\n",
    "    cv2.imwrite(output_name2, output_image2)\n",
    "    cv2.imwrite(output_name3, output_image3)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# ===== Question 3: Laplacian pyramid blending ======\n",
    "# ===================================================\n",
    "\n",
    "\n",
    "def laplacian_pyramid_blending(img_in1, img_in2):\n",
    "    # generate Gaussian pyramid for A\n",
    "    A = img_in1.copy()\n",
    "    #A = cv2.cvtColor(A, cv2.COLOR_BGR2RGB)\n",
    "    A = A[:,:A.shape[0]]\n",
    "    \n",
    "    # generate Gaussian pyramid for B\n",
    "    B = img_in2.copy()\n",
    "    #B = cv2.cvtColor(B, cv2.COLOR_BGR2RGB)\n",
    "    B = B[:A.shape[0],:A.shape[0]]\n",
    "\n",
    "    gpA = [A]\n",
    "    for i in range(6):\n",
    "        A = cv2.pyrDown(gpA[i])\n",
    "        gpA.append(A)\n",
    "    # generate Gaussian pyramid for B\n",
    "    \n",
    "    gpB = [B]\n",
    "    for i in xrange(6):\n",
    "        B = cv2.pyrDown(gpB[i])\n",
    "        gpB.append(B)\n",
    "    # generate Laplacian Pyramid for A\n",
    "    lpA = [gpA[5]]\n",
    "    for i in xrange(5,0,-1):\n",
    "        size = (gpA[i-1].shape[1], gpA[i-1].shape[0])\n",
    "        GE = cv2.pyrUp(gpA[i], dstsize = size)\n",
    "        L = cv2.subtract(gpA[i-1],GE)\n",
    "        lpA.append(L)\n",
    "    # generate Laplacian Pyramid for B\n",
    "    lpB = [gpB[5]]\n",
    "    for i in xrange(5,0,-1):\n",
    "        size = (gpB[i-1].shape[1], gpB[i-1].shape[0])\n",
    "        GE = cv2.pyrUp(gpB[i], dstsize = size)\n",
    "        L = cv2.subtract(gpB[i-1],GE)\n",
    "        lpB.append(L)\n",
    "    # Now add left and right halves of images in each level\n",
    "    LS = []\n",
    "    for la,lb in zip(lpA,lpB):\n",
    "        rows,cols,dpt = la.shape\n",
    "        ls = np.hstack((la[:,0:cols/2], lb[:,cols/2:]))\n",
    "        LS.append(ls)\n",
    "    # now reconstruct\n",
    "    ls_ = LS[0]\n",
    "    for i in xrange(1,6):\n",
    "        size = (LS[i].shape[1], LS[i].shape[0])\n",
    "        ls_ = cv2.pyrUp(ls_, dstsize = size)\n",
    "        ls_ = cv2.add(ls_, LS[i])\n",
    "    # image with direct connecting each half\n",
    "    # Write laplacian pyramid blending codes here\n",
    "    img_out = ls_  # Blending result\n",
    "\n",
    "    return True, img_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question3():\n",
    "\n",
    "    # Read in input images\n",
    "    input_image1 = cv2.imread(sys.argv[2], cv2.IMREAD_COLOR)\n",
    "    input_image2 = cv2.imread(sys.argv[3], cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Laplacian pyramid blending\n",
    "    succeed, output_image = laplacian_pyramid_blending(input_image1, input_image2)\n",
    "    # Write out the result\n",
    "    output_name = sys.argv[4] + \"output3.png\"\n",
    "    cv2.imwrite(output_name, output_image)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: [Question_Number] [Input_Options] [Output_Options]\n",
      "[Question Number]\n",
      "1 Histogram equalization\n",
      "2 Frequency domain filtering\n",
      "3 Laplacian pyramid blending\n",
      "[Input_Options]\n",
      "Path to the input images\n",
      "[Output_Options]\n",
      "Output directory\n",
      "Example usages:\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py 1 [path to input image] [output directory]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py 2 [path to input image1] [path to input image2] [output directory]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py 3 [path to input image1] [path to input image2] [output directory]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    question_number = -1\n",
    "\n",
    "    # Validate the input arguments\n",
    "    if (len(sys.argv) < 4):\n",
    "        help_message()\n",
    "        sys.exit()\n",
    "    else:\n",
    "        question_number = int(sys.argv[1])\n",
    "\n",
    "        if (question_number == 1 and not (len(sys.argv) == 4)):\n",
    "            help_message()\n",
    "            sys.exit()\n",
    "        if (question_number == 2 and not (len(sys.argv) == 5)):\n",
    "            help_message()\n",
    "            sys.exit()\n",
    "        if (question_number == 3 and not (len(sys.argv) == 5)):\n",
    "            help_message()\n",
    "            sys.exit()\n",
    "        if (question_number > 3 or question_number < 1 or len(sys.argv) > 5):\n",
    "            print(\"Input parameters out of bound ...\")\n",
    "            sys.exit()\n",
    "\n",
    "    function_launch = {\n",
    "        1: Question1,\n",
    "        2: Question2,\n",
    "        3: Question3,\n",
    "    }\n",
    "\n",
    "    # Call the function\n",
    "    function_launch[1]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-17d94a2d8837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQuestion1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2dc55ae16f11>\u001b[0m in \u001b[0;36mQuestion1\u001b[0;34m(inp, output)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Histogram equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msucceed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistogram_equalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Write out the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ac7c54fa7678>\u001b[0m in \u001b[0;36mhistogram_equalization\u001b[0;34m(img_in)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Write histogram equalization here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mh_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mh_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "Question1(\"input1.jpg\",\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "  \n",
    "originalImage = cv2.imread('HW1Final/input3256.jpeg')\n",
    "grayImage = cv2.cvtColor(originalImage, cv2.COLOR_BGR2GRAY)\n",
    "(thresh, blackAndWhiteImage) = cv2.threshold(grayImage, 127, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "  \n",
    "cv2.imwrite('blackAndWhiteImage.png', blackAndWhiteImage)\n",
    "cv2.imwrite('grayImage.png', grayImage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
